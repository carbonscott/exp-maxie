checkpoint:
  state_dict_type: full
  chkpt_saving_iterations: null
  preempt_metadata_path: null
  preempt_chkpt_saving_iterations: 30
  directory: experiments/chkpts
  prefix: 633m-ds100+norm_pix_loss+float16
  path_chkpt_prev: null
  pretrain: null
dataset:
  drop_last_in_sampler: true
  drop_last_in_loader: true
  batch_size: 1
  num_workers: 2
  pin_memory: true
  prefetch_factor: 10
  path_train: zarr_paths.abs.sub128_shuffled.parquet
  path_val: zarr_paths.abs.sub128_shuffled.parquet
  seg_size: 60
  transforms:
    H_pad: 980
    W_pad: 980
    Hv: 980
    Wv: 980
    sigma: 0.01
    num_crop: 1
    num_patch: 100
    size_patch: 20
    angle_max: 360
    frac_shift_max: 0.1
    var_size_patch: 0.2
    sampling_fraction: null
    set:
      pad: true
      random_patch: false
      random_rotate: false
      random_shift: false
      instance_norm: false
      polar_center_crop: true
      batch_sampler: false
dist:
  backend: nccl
  uses_unique_world_seed: true
  dtype: float16
logging:
  directory: experiments/logs
  prefix: 633m-ds100+norm_pix_loss+float16
  level: debug
loss:
  grad_accum_steps: 10
lr_scheduler:
  min_lr: 1.0e-07
  total_iterations: 1000000
  warmup_iterations: 10
  scheduler_update_iterations: 1
misc:
  max_epochs: 2000
  max_eval_iter: 20
  max_eval_retry: 2
  sharding_stage: zero3
  compiles_model: false
  data_dump_on: false
  peak_flops_per_sec: 112000000000000
  monitors_dynamics: false
model:
  hf_config:
    hidden_size: 1280
    num_hidden_layers: 32
    num_attention_heads: 16
    intermediate_size: 5120
    hidden_act: gelu
    hidden_dropout_prob: 0.0
    attention_probs_dropout_prob: 0.0
    initializer_range: 0.02
    layer_norm_eps: 1.0e-12
    image_size: 980
    patch_size: 14
    num_channels: 1
    qkv_bias: true
    decoder_num_attention_heads: 16
    decoder_hidden_size: 512
    decoder_num_hidden_layers: 8
    decoder_intermediate_size: 2048
    mask_ratio: 0.75
    norm_pix_loss: true
  from_scratch: false
optim:
  grad_clip: 1.0
  lr: 0.0003
  weight_decay: 0.001
  beta1: 0.9
  beta2: 0.95
  fused: false

# THIS SCRIPT IS GENERATED BY EXECUTING: 
# python launch_job.py job=633m-ds100+norm_pix_loss+float16 auto_submit=true bsub_config.trainer=train.fsdp.py bsub_config.num_gpus_for_client=6 bsub_config.num_nodes=10 bsub_config.walltime=02:00 bsub_config.qos=debug train_config.checkpoint.prefix=633m-ds100+norm_pix_loss+float16 train_config.checkpoint.state_dict_type=full train_config.checkpoint.preempt_metadata_path=preempt/633m-ds100+norm_pix_loss+float16.dat train_config.checkpoint.preempt_chkpt_saving_iterations=30 train_config.checkpoint.chkpt_saving_iterations=null train_config.dataset.path_train=preprocess/zarr_paths.abs.sub128_shuffled.parquet train_config.dataset.path_val=preprocess/zarr_paths.abs.sub128_shuffled.parquet train_config.dataset.num_workers=2 train_config.dataset.prefetch_factor=10 train_config.dataset.pin_memory=true train_config.dataset.seg_size=60 train_config.loss.grad_accum_steps=10 train_config.dataset.batch_size=1 train_config.dataset.transforms.set.pad=true train_config.dataset.transforms.set.polar_center_crop=true train_config.dataset.transforms.set.instance_norm=false train_config.dataset.transforms.set.batch_sampler=false train_config.dataset.transforms.set.random_patch=false train_config.dataset.transforms.set.random_rotate=false train_config.dataset.transforms.set.random_shift=false train_config.dataset.transforms.H_pad=980 train_config.dataset.transforms.W_pad=980 train_config.dataset.transforms.Hv=980 train_config.dataset.transforms.Wv=980 train_config.dataset.transforms.num_crop=1 train_config.model.hf_config.hidden_size=1280 train_config.model.hf_config.num_hidden_layers=32 train_config.model.hf_config.num_attention_heads=16 train_config.model.hf_config.intermediate_size=5120 train_config.model.hf_config.hidden_act=gelu train_config.model.hf_config.hidden_dropout_prob=0.0 train_config.model.hf_config.attention_probs_dropout_prob=0.0 train_config.model.hf_config.initializer_range=0.02 train_config.model.hf_config.image_size=980 train_config.model.hf_config.patch_size=14 train_config.model.hf_config.num_channels=1 train_config.model.hf_config.qkv_bias=true train_config.model.hf_config.decoder_num_attention_heads=16 train_config.model.hf_config.decoder_hidden_size=512 train_config.model.hf_config.decoder_num_hidden_layers=8 train_config.model.hf_config.decoder_intermediate_size=2048 train_config.model.hf_config.mask_ratio=0.75 train_config.model.hf_config.norm_pix_loss=true train_config.optim.lr=0.0003 train_config.optim.fused=false train_config.misc.monitors_dynamics=false train_config.misc.compiles_model=false train_config.misc.max_epochs=2000 train_config.misc.max_eval_iter=20 train_config.misc.sharding_stage=zero3 train_config.misc.peak_flops_per_sec=112000000000000 train_config.lr_scheduler.warmup_iterations=10 train_config.lr_scheduler.total_iterations=1000000 train_config.logging.prefix=633m-ds100+norm_pix_loss+float16 train_config.dist.dtype=float16
